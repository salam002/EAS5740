{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE0Wtid5TxAI"
      },
      "outputs": [],
      "source": [
        "#Track 1: Customer Segmentation\n",
        "\n",
        "# Can you identify distinct user segments based on their reviews?\n",
        "# Ans: yes, cluster 0, 1, 2, 3.\n",
        "# Cluster Summary:\n",
        "# Cluster 0: 16007 users (35.56%)\n",
        "# Cluster 1: 9901 users (21.99%)\n",
        "# Cluster 2: 15049 users (33.43%)\n",
        "# Cluster 3: 4062 users (9.02%)\n",
        "\n",
        "# What are the key characteristics of each segment?\n",
        "# Ans: cluster 0 are 'enthusiastic users' who are enthusiastic about writing reviews and have many fans.\n",
        "# Ans: cluster 3 are 'invisible users' who normally won't give reviews, tend to give lower scores and don't have many fans.\n",
        "# Ans: cluster 1 are 'regular, picky users' who are not very active nor invisible, and tend to give relatively low score.\n",
        "# Ans: cluster 2 are 'regular, undemanding users' who are not very active nor invisible, and tend to give relatively high score.\n",
        "# Cluster Means:\n",
        "# Cluster                      0       1       2       3  Overall\n",
        "# avg_review_length       585.96  646.60  405.70  621.28   542.23\n",
        "# review_frequency         11.04    5.16    5.42    0.94     6.96\n",
        "# category_diversity        6.04    5.38    5.56    4.96     5.64\n",
        "# avg_rating_deviation      0.48   -1.35    0.76   -1.56    -0.02\n",
        "# engagement_score       1030.35  217.44  196.60   12.77   481.05\n",
        "# tenure_days            4965.37 3859.08 3148.60 3136.83  3949.77\n",
        "# average_stars_usercsv     3.91    3.35    4.36    1.67     3.73\n",
        "# compliment_hot_usercsv   23.16    3.52    2.58    0.01     9.88\n",
        "# fans_usercsv             15.43    3.23    3.33    0.12     7.32\n",
        "# review_count_usercsv    155.12   56.77   46.70    8.29    84.00\n",
        "\n",
        "# How can marketing strategies be tailored to each segment to promote businesses and increase their customer base?\n",
        "# Ans: cluster 0, compared to other clusters, care more about bike parking and reservation, so we can promote those when marketing.\n",
        "# Ans: cluster 1, compared to other clusters, care more about bike RestaurantsTableService and AcceptsCreditCards, so we can promote those when marketing.\n",
        "# Ans: cluster 2, compared to other clusters, care more about caters, AcceptsCreditCards and OutdoorSeating, so we can promote those when marketing.\n",
        "# Ans: cluster 3, compared to other clusters, care more about GoodForKids, HasTV and Delivery, so we can promote those when marketing.\n",
        "# Business Attribute Ratios by Cluster (% of 'TRUE' values):\n",
        "# Cluster                                                 0       1       2       3 Overall\n",
        "# attributes.GoodForKids_businesscsv                 77.92%  82.15%  83.43%  84.31%  80.99%\n",
        "# attributes.DogsAllowed_businesscsv                 25.74%  24.93%  27.32%  23.22%  26.01%\n",
        "# attributes.RestaurantsDelivery_businesscsv         62.92%  66.75%  69.26%  72.00%  66.43%\n",
        "# attributes.Caters_businesscsv                      54.44%  55.44%  59.07%  58.14%  56.40%\n",
        "# attributes.RestaurantsTableService_businesscsv     75.22%  76.95%  75.99%  74.52%  75.82%\n",
        "# attributes.OutdoorSeating_businesscsv              64.49%  61.94%  67.34%  58.80%  64.47%\n",
        "# attributes.HasTV_businesscsv                       70.29%  75.84%  73.30%  80.19%  73.11%\n",
        "# attributes.BusinessAcceptsCreditCards_businesscsv  96.02%  97.21%  97.21%  96.99%  96.73%\n",
        "# attributes.BikeParking_businesscsv                 82.85%  80.21%  81.75%  75.96%  81.46%\n",
        "# attributes.RestaurantsReservations_businesscsv     47.68%  46.43%  45.61%  41.22%  46.32%\n",
        "# attributes.DriveThru_businesscsv                   24.69%  30.33%  24.01%  43.93%  27.48%\n",
        "# attributes.Open24Hours_businesscsv                 26.53%  10.00%  41.18%  28.57%  27.71%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIAvdRwvT3B1"
      },
      "outputs": [],
      "source": [
        "# import necessary modules\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3fzcNHaT5Ae"
      },
      "outputs": [],
      "source": [
        "##########################################################\n",
        "# Please update the \"File paths\" part below before running\n",
        "##########################################################\n",
        "# File paths\n",
        "business_path = '/Users/sz229/Desktop/EAS Project/Data/business.csv'\n",
        "review_path = '/Users/sz229/Desktop/EAS Project/Data/review.csv'\n",
        "user_path = '/Users/sz229/Desktop/EAS Project/Data/user.csv'\n",
        "\n",
        "# Load the datasets\n",
        "business_df = pd.read_csv(business_path)\n",
        "review_df = pd.read_csv(review_path)\n",
        "user_df = pd.read_csv(user_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rawvDW4lUppf"
      },
      "source": [
        "# PART 1: Cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GopN75dFUEgA"
      },
      "outputs": [],
      "source": [
        "# Add suffixes to all columns before merging to make sure we track the right attributes\n",
        "business_df.columns = [f\"{col}_businesscsv\" for col in business_df.columns]\n",
        "review_df.columns = [f\"{col}_reviewcsv\" for col in review_df.columns]\n",
        "user_df.columns = [f\"{col}_usercsv\" for col in user_df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1XgxYc8UIrq"
      },
      "outputs": [],
      "source": [
        "# Rename the 'business_id' and 'user_id' columns back to their original names for merging\n",
        "business_df = business_df.rename(columns={'business_id_businesscsv': 'business_id'})\n",
        "review_df = review_df.rename(columns={'business_id_reviewcsv': 'business_id', 'user_id_reviewcsv': 'user_id'})\n",
        "user_df = user_df.rename(columns={'user_id_usercsv': 'user_id'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imgGYhQ6UKhU"
      },
      "outputs": [],
      "source": [
        "# Merge datasets\n",
        "merged_df = review_df.merge(business_df, on='business_id')\n",
        "merged_df = merged_df.merge(user_df, on='user_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ_debXEUMEG"
      },
      "outputs": [],
      "source": [
        "# Function to display basic information about a dataframe\n",
        "def display_df_info(df, name):\n",
        "    print(f\"\\n--- {name} Dataset ---\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(\"\\nColumn names:\")\n",
        "    print(df.columns.tolist())\n",
        "    print(\"\\nData types:\")\n",
        "    print(df.dtypes)\n",
        "    print(\"\\nMissing values:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\nSample data:\")\n",
        "    print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cucmg2uUOns"
      },
      "outputs": [],
      "source": [
        "# Display information for the merged dataset\n",
        "display_df_info(merged_df, \"Merged\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdZGzsQoURCi"
      },
      "outputs": [],
      "source": [
        "# Function to plot distribution of a numerical column\n",
        "def plot_distribution(df, column, title):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df[column], kde=True)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDPcpQ9vUSvI"
      },
      "outputs": [],
      "source": [
        "# Plot distributions of some variables\n",
        "plot_distribution(merged_df, 'stars_reviewcsv', 'Distribution of Review Stars')\n",
        "plot_distribution(merged_df, 'average_stars_usercsv', 'Distribution of User Average Stars')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y52nAx9IUUU-"
      },
      "outputs": [],
      "source": [
        "# Select relevant numerical columns for correlation analysis\n",
        "numerical_columns = ['stars_reviewcsv', 'useful_reviewcsv', 'funny_reviewcsv', 'cool_reviewcsv',\n",
        "                     'review_count_usercsv', 'useful_usercsv', 'funny_usercsv', 'cool_usercsv',\n",
        "                     'fans_usercsv', 'average_stars_usercsv', 'compliment_hot_usercsv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajNibxNvUXus"
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix round 2 decimal\n",
        "correlation_matrix = merged_df[numerical_columns].corr()\n",
        "correlation_matrix_rounded = correlation_matrix.round(2)\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_matrix_rounded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfQkt0eRUbXU"
      },
      "outputs": [],
      "source": [
        "# Find the highest correlations\n",
        "correlations = correlation_matrix.unstack()\n",
        "correlations = correlations[correlations < 1.0]  # remove self-corr\n",
        "high_correlations = correlations.sort_values(ascending=False).head(10)\n",
        "\n",
        "print(\"\\nTop 10 Highest Correlations:\")\n",
        "print(high_correlations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6qEfw8LUfBN"
      },
      "outputs": [],
      "source": [
        "# Print summary statistics\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(merged_df[numerical_columns].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kqrpAFWUgf6"
      },
      "outputs": [],
      "source": [
        "# Identify and print top categories\n",
        "top_categories = merged_df['categories_businesscsv'].str.split(', ', expand=True).stack().value_counts().head(10)\n",
        "print(\"\\nTop 10 Business Categories:\")\n",
        "print(top_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifb-nZFdUi9r"
      },
      "source": [
        "# PART 2: Add more features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u3kbFuIUnY6"
      },
      "outputs": [],
      "source": [
        "# 1. Average review length\n",
        "merged_df['review_length_reviewcsv'] = merged_df['text_reviewcsv'].str.len()\n",
        "merged_df['avg_review_length'] = merged_df.groupby('user_id')['review_length_reviewcsv'].transform('mean')\n",
        "\n",
        "print(merged_df['avg_review_length'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIa7y91fUzZ-"
      },
      "outputs": [],
      "source": [
        "# 2. Frequency of reviews (reviews per year)\n",
        "merged_df['yelping_since_usercsv'] = pd.to_datetime(merged_df['yelping_since_usercsv'])\n",
        "current_date = pd.Timestamp.now()\n",
        "merged_df['years_on_yelp'] = (current_date - merged_df['yelping_since_usercsv']).dt.total_seconds() / (365.25 * 24 * 60 * 60)\n",
        "merged_df['review_frequency'] = merged_df['review_count_usercsv'] / merged_df['years_on_yelp']\n",
        "\n",
        "print(merged_df['review_frequency'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjpwf3qvU5Kl"
      },
      "outputs": [],
      "source": [
        "# 3. Diversity of businesses reviewed (unique categories)\n",
        "# First, we need to explode the categories and count unique ones per user\n",
        "categories_df = merged_df.groupby('user_id')['categories_businesscsv'].apply(\n",
        "    lambda x: pd.Series(x.str.split(', ', expand=True).values.ravel()).dropna().unique()\n",
        ")\n",
        "merged_df['category_diversity'] = merged_df['user_id'].map(categories_df.str.len())\n",
        "\n",
        "print('category_diversity', merged_df['category_diversity'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STucOKF3U9XZ"
      },
      "outputs": [],
      "source": [
        "# 4. Average rating deviation (how much a user's ratings deviate from the business average)\n",
        "merged_df['rating_deviation'] = merged_df['stars_reviewcsv'] - merged_df['stars_businesscsv']\n",
        "merged_df['avg_rating_deviation'] = merged_df.groupby('user_id')['rating_deviation'].transform('mean')\n",
        "\n",
        "print('avg_rating_deviation', merged_df['avg_rating_deviation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XutiGZp_U_ZW"
      },
      "outputs": [],
      "source": [
        "# 5. Engagement score (combination of useful, funny, and cool votes received)\n",
        "merged_df['engagement_score'] = (merged_df['useful_usercsv'] +\n",
        "                                 merged_df['funny_usercsv'] +\n",
        "                                 merged_df['cool_usercsv'])\n",
        "\n",
        "print('engagement_score', merged_df['engagement_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1AIQ9sjVA3r"
      },
      "outputs": [],
      "source": [
        "# 6. Tenure as days (how long a user has been with Yelp)\n",
        "merged_df['yelping_since_usercsv'] = pd.to_datetime(merged_df['yelping_since_usercsv'])\n",
        "merged_df['tenure_days'] = (pd.Timestamp.now() - merged_df['yelping_since_usercsv']).dt.days\n",
        "\n",
        "print('tenure_days', merged_df['tenure_days'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37BX7D2_VCkk"
      },
      "source": [
        "# PART 3: Feature preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DjKq1m4VF6q"
      },
      "outputs": [],
      "source": [
        "# Select features for clustering\n",
        "clustering_features = [\n",
        "    'avg_review_length',\n",
        "    'review_frequency',\n",
        "    'category_diversity',\n",
        "    'avg_rating_deviation',\n",
        "    'engagement_score',\n",
        "    'tenure_days',\n",
        "\n",
        "    'average_stars_usercsv',\n",
        "    'compliment_hot_usercsv',\n",
        "    'fans_usercsv',\n",
        "    #'friends_usercsv' # see how number of friends can influence user activity\n",
        "    'review_count_usercsv',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3hEQa_8VKTs"
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe with one row per user, using the mean of their features\n",
        "user_features_df = merged_df.groupby('user_id')[clustering_features].mean().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KOI9KWYVL7e"
      },
      "outputs": [],
      "source": [
        "# Function to normalize a column using Min-Max scaling\n",
        "def normalize_column(column):\n",
        "    min_val = column.min()\n",
        "    max_val = column.max()\n",
        "    return (column - min_val) / (max_val - min_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CDsX0adVNh8"
      },
      "outputs": [],
      "source": [
        "# Normalize features\n",
        "user_features_normalized = user_features_df.copy()\n",
        "for feature in clustering_features:\n",
        "    user_features_normalized[f'{feature}_normalized'] = normalize_column(user_features_normalized[feature])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6TT5UdCVPEB"
      },
      "outputs": [],
      "source": [
        "# Keep only normalized features and user_id\n",
        "columns_to_keep = [f'{feature}_normalized' for feature in clustering_features] + ['user_id']\n",
        "user_features_normalized = user_features_normalized[columns_to_keep]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkYo1pFlVQ1d"
      },
      "outputs": [],
      "source": [
        "# Display info about the new features\n",
        "print(\"#################################\")\n",
        "print(user_features_normalized.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihj24h4HVVuA"
      },
      "source": [
        "# PART 4: Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn1dmfMqVYok"
      },
      "outputs": [],
      "source": [
        "# Load the normalized user features\n",
        "user_features = user_features_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LP8zBmXVa6O"
      },
      "outputs": [],
      "source": [
        "# Select the features for clustering\n",
        "clustering_features = [\n",
        "    'avg_review_length_normalized',\n",
        "    'review_frequency_normalized',\n",
        "    'category_diversity_normalized',\n",
        "    'avg_rating_deviation_normalized',\n",
        "    'engagement_score_normalized',\n",
        "    'tenure_days_normalized',\n",
        "    'average_stars_usercsv_normalized',\n",
        "    'compliment_hot_usercsv_normalized',\n",
        "    'fans_usercsv_normalized',\n",
        "    'review_count_usercsv_normalized',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_0DJqAbVc7u"
      },
      "outputs": [],
      "source": [
        "# Extract features for clustering\n",
        "X = user_features[clustering_features].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J66COq-VeW5"
      },
      "outputs": [],
      "source": [
        "# Implement elbow method\n",
        "def elbow_method(X, max_k):\n",
        "    inertias = []\n",
        "    for k in range(1, max_k + 1):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        kmeans.fit(X)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "    return inertias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnHzisWbVf-d"
      },
      "outputs": [],
      "source": [
        "# Run elbow method\n",
        "max_k = 10\n",
        "inertias = elbow_method(X, max_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKD7oZneVhl_"
      },
      "outputs": [],
      "source": [
        "# Plot elbow curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, max_k + 1), inertias, marker='o')\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIKKfdgyVkxZ"
      },
      "outputs": [],
      "source": [
        "# Determine optimal k\n",
        "optimal_k = 4\n",
        "\n",
        "# Perform final clustering with optimal k\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "labels = kmeans.fit_predict(X)\n",
        "\n",
        "# Add cluster labels to the user features dataframe\n",
        "user_features['Cluster'] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SU5lHrmVqcM"
      },
      "outputs": [],
      "source": [
        "# Print summary of clusters\n",
        "print(\"\\nCluster Summary:\")\n",
        "for i in range(optimal_k):\n",
        "    cluster_size = sum(labels == i)\n",
        "    print(f\"Cluster {i}: {cluster_size} users ({cluster_size/len(labels)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_PQCCR3Vr16"
      },
      "outputs": [],
      "source": [
        "# Calculate and print cluster centroids\n",
        "cluster_centroids = pd.DataFrame(kmeans.cluster_centers_, columns=clustering_features)\n",
        "print(\"\\nCluster Centroids:\")\n",
        "print(cluster_centroids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMXe4Cw2Vw1z"
      },
      "source": [
        "**PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2btgUYvLVtrx"
      },
      "outputs": [],
      "source": [
        "#########PCA#########\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb60Cf43VwT8"
      },
      "outputs": [],
      "source": [
        "# Visualize clusters using PCA\n",
        "plt.figure(figsize=(10, 8))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis')\n",
        "plt.scatter(pca.transform(kmeans.cluster_centers_)[:, 0],\n",
        "            pca.transform(kmeans.cluster_centers_)[:, 1],\n",
        "            marker='x', s=200, linewidths=3, color='red', label='Centroids')\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')\n",
        "plt.title('Customer Segments (PCA)')\n",
        "plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-B1xg0-V2Xt"
      },
      "source": [
        "# PART 5: Post-Segmentation Analytics for each cluster: characteristics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za5w-5-6V0eC"
      },
      "outputs": [],
      "source": [
        "# Merge the cluster labels to the original dataset using user_id\n",
        "user_features_df = user_features_df.merge(user_features_normalized[['user_id', 'Cluster']],\n",
        "                                          on='user_id',\n",
        "                                          how='left',\n",
        "                                          validate='one_to_one')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKYMZCOnV5lP"
      },
      "outputs": [],
      "source": [
        "# Check if any users are missing cluster labels\n",
        "missing_clusters = user_features_df['Cluster'].isnull().sum()\n",
        "if missing_clusters > 0:\n",
        "    print(f\"Warning: {missing_clusters} users are missing cluster labels.\")\n",
        "else:\n",
        "    print(\"All users have been assigned cluster labels successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsbUJOAYV71T"
      },
      "outputs": [],
      "source": [
        "# Display summary statistics for each cluster\n",
        "# List of features we want to analyze\n",
        "features = [\n",
        "    'avg_review_length', 'review_frequency', 'category_diversity',\n",
        "    'avg_rating_deviation', 'engagement_score', 'tenure_days',\n",
        "    'average_stars_usercsv', 'compliment_hot_usercsv', 'fans_usercsv',\n",
        "    'review_count_usercsv'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSAWgk0AV9kS"
      },
      "outputs": [],
      "source": [
        "# Calculate means for each cluster\n",
        "cluster_means = user_features_df.groupby('Cluster')[features].mean()\n",
        "\n",
        "# Calculate overall means\n",
        "overall_means = user_features_df[features].mean()\n",
        "\n",
        "# Transpose the DataFrame for a more compact display\n",
        "cluster_means_t = cluster_means.T\n",
        "\n",
        "# Add overall means as a column\n",
        "cluster_means_t['Overall'] = overall_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0LM6PDpWEU7"
      },
      "outputs": [],
      "source": [
        "# Format the output\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "print(\"Cluster Means:\")\n",
        "print(cluster_means_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2i9XG0bWFtS"
      },
      "source": [
        "# PART 6: Post-Segmentation Analytics for each cluster: business categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQlAlpbfWIxx"
      },
      "outputs": [],
      "source": [
        "# Merge the cluster labels back to merged_df\n",
        "merged_df_with_clusters = merged_df.merge(user_features_df[['user_id', 'Cluster']], on='user_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAfd7sjkWLEp"
      },
      "outputs": [],
      "source": [
        "# Function to get top categories for a given cluster\n",
        "def get_top_categories(df, cluster):\n",
        "    cluster_data = df[df['Cluster'] == cluster]\n",
        "    categories = cluster_data['categories_businesscsv'].str.split(', ', expand=True).stack()\n",
        "    return categories.value_counts().head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQlDmAJKWMSg"
      },
      "outputs": [],
      "source": [
        "# Get top 10 categories for each cluster\n",
        "for cluster in merged_df_with_clusters['Cluster'].unique():\n",
        "    print(f\"\\nTop 10 Business Categories for Cluster {cluster}:\")\n",
        "    top_categories = get_top_categories(merged_df_with_clusters, cluster)\n",
        "    print(top_categories)\n",
        "    print(\"=================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyhCJFKAWOXQ"
      },
      "source": [
        "# PART 7: Post-Segmentation Analytics for each cluster: business attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwvPTwbWWQYO"
      },
      "outputs": [],
      "source": [
        "# List of attributes we want to analyze\n",
        "attributes = [\n",
        "    'attributes.GoodForKids_businesscsv',\n",
        "    'attributes.DogsAllowed_businesscsv',\n",
        "    'attributes.RestaurantsDelivery_businesscsv',\n",
        "    'attributes.Caters_businesscsv',\n",
        "    'attributes.RestaurantsTableService_businesscsv',\n",
        "    'attributes.OutdoorSeating_businesscsv',\n",
        "    'attributes.HasTV_businesscsv',\n",
        "    'attributes.BusinessAcceptsCreditCards_businesscsv',\n",
        "    'attributes.BikeParking_businesscsv',\n",
        "    'attributes.RestaurantsReservations_businesscsv'\n",
        "    'attributes.DriveThru_businesscsv',\n",
        "    'atrributes.Open24Hours_businesscsv'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAhCgF4aWSMR"
      },
      "outputs": [],
      "source": [
        "# Check data types and unique values\n",
        "print(\"Data types:\")\n",
        "print(merged_df_with_clusters[attributes].dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UbZ1H-qWT3S"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the ratio of 'TRUE' values\n",
        "def true_ratio(series):\n",
        "    true_values = series.astype(str).str.lower() == 'true'\n",
        "    total_values = series.notna()\n",
        "    return true_values.sum() / total_values.sum() if total_values.sum() > 0 else np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lxmQe1yWVOV"
      },
      "outputs": [],
      "source": [
        "# Calculate ratios for each attribute by cluster\n",
        "attribute_ratios = merged_df_with_clusters.groupby('Cluster')[attributes].apply(lambda x: x.apply(true_ratio))\n",
        "\n",
        "# Calculate overall ratios\n",
        "overall_ratios = merged_df_with_clusters[attributes].apply(true_ratio)\n",
        "\n",
        "# Add overall ratios as a new row instead of a column\n",
        "attribute_ratios.loc['Overall'] = overall_ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l9NjBvjWX2o"
      },
      "outputs": [],
      "source": [
        "# Function to format percentages\n",
        "def format_percentage(x):\n",
        "    return f\"{x:.2%}\" if pd.notna(x) else \"N/A\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOAPopo3WY8A"
      },
      "outputs": [],
      "source": [
        "# Apply formatting\n",
        "attribute_ratios_pct = attribute_ratios.apply(lambda col: col.map(format_percentage))\n",
        "\n",
        "# Transpose for better readability\n",
        "attribute_ratios_pct = attribute_ratios_pct.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz5wZ4DdWaG5"
      },
      "outputs": [],
      "source": [
        "# Display the results\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.width', None)  # Autodetect display width\n",
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "\n",
        "print(\"\\nBusiness Attribute Ratios by Cluster (% of 'TRUE' values):\")\n",
        "print(attribute_ratios_pct)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
